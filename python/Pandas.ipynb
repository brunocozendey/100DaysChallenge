{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importando a biblioteca."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na bibliteca pandas existem dois tipos de objetos principais: o DataFrame e as Séries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataFrame\n",
    "\n",
    "É uma tabela, ele possui um array de entradas individuais, cada uma delas possui um certo valor. Cada entrada corresponde a uma linha (ou record) e uma coluna.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Yes': [50, 21], 'No': [131, 2]})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The list of row labels used in a DataFrame is known as an Index. We can assign values to it by using an index parameter in our constructor:\n",
    "\n",
    "Estamos usando o construtor pd.DataFrame() para gerar esses objetos DataFrame. A sintaxe para declarar um novo DataFrame é um dicionário no qual as chaves são o \"Sim, Não\", e os valores são as entradas das listas. Esse é um padrão de construir um novo DataFrame e é o mais encontrado.\n",
    "\n",
    "O Construtor da lista de dicionários associa valores aos títulos das colunas, um caso comum é uma contagem a partir do 0. (0,1,2,3, ...) para as novas linhas de títulos (label). As vezes está Ok, mas frequentemente será interessantes nomear esses títulos.\n",
    "\n",
    "A lista das linhas de títulos, usado em um DataFrame é conhecido como Index. Podemos associar valores a ele usando um parâmetro do Index no construtor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'Bob': ['I liked it.', 'It was awful.'], \n",
    "              'Sue': ['Pretty good.', 'Bland.']},\n",
    "             index=['Product A', 'Product B'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Series\n",
    "As séries por contraste são uma sequencia de valores. Se o DataFrame é uma tabela, a série é uma lista. E você pode criar uma série com uma simples lista.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([1,2,3,4,5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A série em essência é uma simples coluna do DataFrame. Então pode associar colunas a valores assim como no DataFrame, usando o parâmetro do Index. Porém como a Série só tem uma coluna ela e chamada de \"name\".\n",
    "Ex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.Series([30, 35, 40], index=['2015 Sales', '2016 Sales', '2017 Sales'], name='Product A')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "É interessante pensar em um DataFrame como uma coleção, sequenia de Séries junta."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lendo arquivos\n",
    "\n",
    "Data can be stored in any of a number of different forms and formats. By far the most basic of these is the humble CSV file. When you open a CSV file you get something that looks like this:\n",
    "\n",
    "Vimos que somos capaz de criar um DataFrame ou série na mão, mas na maioria das vezes, não será feito dessa forma. No geral trabalhamos com dados já existentes. \n",
    "\n",
    "Dados podem ser armazenados em diferentes formas e formatos. E o tipo mais comum é o CSV. Que quando aberto é algo do tipo:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Product A,Product B,Product C,\n",
    "30,21,9,\n",
    "35,34,1,\n",
    "41,11,11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deixando de lado os datasets exemplos, vemos um dataset real, quando lemos em um DataFrame. Para isso utilizamos, é a função pd.read_csv(), que lê dados em DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv(\"/home/bruno/Documents/Python/100DaysChallenge/python/input/melb_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos usar o atributo .shape, para verificar a quantidade de dados por coluna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isto quer dizer que o DataSet escolhido possui 18.396 linhas com 22 colunas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos verificar algunas valores iniciais com o comando head(), que exibe as 5 primeiras linhas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pd.read_csv() function is well-endowed, with over 30 optional parameters you can specify. For example, you can see in this dataset that the CSV file has a built-in index, which pandas did not pick up on automatically. To make pandas use that column for the index (instead of creating a new one from scratch), we can specify an index_col.\n",
    "\n",
    "A função pd.read_csv() é bem completa, com mais de 30 parâmetros opcionais para especificar. Por exemplo, é possível ver que o Dataset possui um index, que o panda náo pode pegar automaticamente. Para fazer com que o Panda use uma coluna como index(ao inves de criar um do zero), podemos especificar isso como um index_col."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "houses = pd.read_csv(\"/home/bruno/Documents/Python/100DaysChallenge/python/input/melb_data.csv\", index_col=0)\n",
    "houses.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indexando, selecionando e associando dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selecionar valores específicos de DataFrames ou Séries para trabalhar, é um passo implícito em qualquer operação de análise de dados. Uma das primeiras coisas para aprender a trabalhar com dados em Python é como selecionar dados relevantes de forma rápida e efetiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Naive Accessors\n",
    "\n",
    "Objetos nativos no python fornecem uma boa forma de indexar dados. O Panda se preocupa com esse tipo de objeto.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Python podemos acessar a propriedade de um objeto, acessando seu atributo. Um objeto livro por exemplo, deve ter uma propriedade titulo, que pode ser acessada da forma. livro.titulo. \n",
    "\n",
    "As colunas de um DataFrame panda, são acessadas da mesma forma: nome_df.coluna. \n",
    "\n",
    "Se nós temos um dicionário em Python, nós podemos acessar seu valores usando um operador de index([]). E podemos fazer o mesmo com as colunas de um DataFrame.\n",
    "\n",
    "datafame['coluna']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the two ways of selecting a specific Series out of a DataFrame. Neither of them is more or less syntactically valid than the other, but the indexing operator [] does have the advantage that it can handle column names with reserved characters in them (e.g. if we had a country providence column, reviews.country providence wouldn't work).\n",
    "\n",
    "Doesn't a pandas Series look kind of like a fancy dictionary? It pretty much is, so it's no surprise that, to drill down to a single specific value, we need only use the indexing operator [] once more:\n",
    "\n",
    "Há duas formas de selecionar uma série específica de um DataFrame. Nenhum possui uma forma sintática melhor do que a outra, mas o operador de index[] tem avantagem de lidar com o nome da coluna com carcateres reservados, como por exemplo um espaço. \n",
    "\n",
    "Como o DataFrame em Pandas é muito parecido com um dicionário, não é surpresa que para pegar um único item de um dataframe basta adicionar um operador de index[].\n",
    "\n",
    "logo: dataframe['coluna'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Indexando no Pandas\n",
    "\n",
    "O operador de indexação e atributo de seleção são ótimos, pois funcionam como todo o ecosistema em Python. No entando Pandas tem seu próprio operador acessor: loc e iloc, para operações mais avançadas. \n",
    "\n",
    "**Index-based selection**\n",
    "O trabalho de indexação do pandas trabalha em um dos dois paradigmas. O primeiro na base de indexação por seleção: selecionando o banco de dados com a posição numérica nos dados. (iloc)\n",
    "\n",
    "Para selecionar a primeira linha de dados em um DataFrame, usamos o seguinte:\n",
    "\n",
    "dataframe.iloc[0]\n",
    "\n",
    "Utilizando o operador \":\" nativo do Python, significa \"tudo\". Quando combinado com outros seletores, portanto eleepode ser usado para indicar um range de valores. Por exemplo selecionar as 3 primeiras linhas de um DataFrame:\n",
    "\n",
    "dataframe.iloc[:3,0]\n",
    "\n",
    "Ou pode selecionar da segunda a terceira entrada:\n",
    "\n",
    "dataframe.iloc[1:3,0]\n",
    "\n",
    "Também é possível passar uma lista de entradas:\n",
    "\n",
    "dataframe.iloc[[0,1,2],0]\n",
    "\n",
    "Finalmente é interessante saber que números negativos podem ser usados para seleção. Isso irá começar contar de trás para frente do começo para o íncio. Por exemplo pegar as 5 últimas entradas:\n",
    "\n",
    "dataframe.iloc[-5:]\n",
    "\n",
    "**Label-based selction**\n",
    "\n",
    "O segundo paradigma para seleção de atributo é seguida pelo operador loc, que é a seleção label-based. Neste paradigma, o valor do index do dado a posição não importa.\n",
    "\n",
    "Por exemplo, pegar as primeiras entradas do dataframe:\n",
    "\n",
    "dataFrame.loc[:, ['taster_name', 'taster_twitter_handle', 'points']]\n",
    "\n",
    "**Escolhendo entre loc e iloc**\n",
    "\n",
    "Quando escolher o loc ou iloc, levar em considereção que os dois usam esquemas de indexação um pouco diferentes. \n",
    "\n",
    "O iloc usa o esquema de indexação do Python stdlib, onde o primeiro elemento do range está incluso e o último excluído. Então o 0:10 irá selecionar as entradas de 0 a 9. loc, por outro lado, incluí inclusivamente. Então de 0:10 irá selecionar as entradas de 0 a 10 inclusive. \n",
    "\n",
    "Lembrar que o loc pode indexar qualquer tipo de stdlib: strings, por exemplo. Se tivemos um DataFrame com valores de index como \"Apples\", ... , \"Potatoes\", e nós queremos selecionar todas as escolhas de frutas alfabéticas entre \"Apple\"e \"Potatoe\", então é muito mais conveniente para indexar usar o dataFrame.loc['Apples':'Potatoes'].\n",
    "\n",
    "Isto é particularmente confuso, quando o index do DataFrame é uma lista simples numérico, ex 0 a 1000. Neste caso, dataFrame.iloc[0:1000] irá retornar 1000 entradas, enquanto dataFrame.loc[0:1000] retorna 1001 deles. Para pegar 1000 elementos usando o loc, você precisará diminuir 1 fazendo dataFrame.iloc[0:999].\n",
    "\n",
    "Por outro lado, a semantica do loc são as mesmas para o iloc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulando o index\n",
    "\n",
    "A seleção label-based da uma força para as labels nos index. O index que nós utilizamos não são imutáveis. Nós podemos manipular o index de qualquer forma que encaixe. \n",
    "\n",
    "O método set_index() pode ser usado para fazer esse trabalho, como por exemplo:\n",
    "\n",
    "dataFrame.set_index(\"title\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleção condicional\n",
    "\n",
    "Tão logo, nós indexamos várias partes dos dados, usando propriedades estruturais do pŕprio DataFrame. Para fazer algo interessante com estes dados, precisamos normalmente fazer perguntas condicionais.\n",
    "\n",
    "Por exemplo, suponha que estejamos interessado em coletar dados de uma determinada nacionalidade, como a Itália.\n",
    "\n",
    "Podemos iniciar checando se aquele dado está atribuído a itátlia ou não:\n",
    "\n",
    "dataFrame.country == 'Italy'\n",
    "\n",
    "Esta operação produz uma série de True/False basedo no país de cada entrada. Este resultado pode ser utilizado dentro de um loc para selecionar dados relevantes:\n",
    "\n",
    "dataFrame.loc[dataFrame.country == 'Italy']\n",
    "\n",
    "Podemos utilizar mais de uma entrada por exemplo, podemos levar em consideração a quantidade de pontos, utilizando o operador (&):\n",
    "\n",
    "dataFrame.loc[(dataFrame.country == 'Italy') & (dataFrame.points >= 90)]\n",
    "\n",
    "Pode ser utilizado também o operador ou (|):\n",
    "\n",
    "dataFrame.loc[(dataFrame.country == 'Italy') | (dataFrame.points >= 90)]\n",
    "\n",
    "O Pandar também vem com alguns seletores condicionar internos, dois são destacados em seguida:\n",
    "- isin: Seleciona o valor que \"is in\", está em uma lista de valores. Por exemplo abaixo poderia selecionar dados que são da Italia e da França:\n",
    "\n",
    "dataFrame.loc[dataFrame.country.isin(['Italy', 'France'])]\n",
    "\n",
    "- isnull (ou notnull): São métodos que destaca valores que são (ou não são) vazios, nulos. Por exemplo se quiser achar alguma entrada de preço que não foi digitado:\n",
    "\n",
    "dataFrame.loc[dataFrame.price.notnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Associando dados**\n",
    "\n",
    "Associar dados a um DataFrame é fácil, para colocar valores constantes, pode fazer da seguinte forma:\n",
    "\n",
    "dataFrame['critic'] = 'everyone'\n",
    "\n",
    "Ou com valores iteraveis:\n",
    "\n",
    "dataFrame['index_backwards'] = range(len(dataFrame), 0, -1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funções Summary e Mapping\n",
    "\n",
    "Além de remover items que não interessa para análise, há a necessidade de formatar algum dado que não está de forma correta. Então em certos momentos precisamos manipular estes dados.\n",
    "\n",
    "**Funções de resumo (Summary functions)**\n",
    "\n",
    "Função que exibe alguns dados estatísticos.\n",
    "\n",
    "> dataFrame.coluna.describe()\n",
    "\n",
    "Faz sentido para dados numéricos.\n",
    "\n",
    "Para ver a média:\n",
    "\n",
    "> dataFrame.coluna.mean()\n",
    "\n",
    "Para ver a lista de valores unicos:\n",
    "\n",
    "> dataFrame.coluna.unique()\n",
    "\n",
    "Para verificar a frequencia com que valores únicos ocorrem no dataset:\n",
    "\n",
    "> dataFrame.coluna.value_counts()\n",
    "\n",
    "** Maps **\n",
    "\n",
    "Map é um termo que vem da matemática, para uma função que pega um conjunto de valores e os \"mapeia\" em outro conjunto de valor. Em Ciência de Dados frequentemente precisamos criar uma represetação de um dado existente, ou transformar um dado em um formato, em um formato que desejamos. Maps lidam bem com esse tipo de trabalho, sendo importante para fazer certas análises.\n",
    "\n",
    "Existem 2 métodos de mapeamento.\n",
    "\n",
    "* map(): é o primeiro e o mais simples.\n",
    "\n",
    "Supondo que queremos passar alguns pontos na média para 0, podemos fazer da seguinte forma:\n",
    "\n",
    ">review_points_mean = reviews.points.mean()\n",
    ">reviews.points.map(lambda p: p - review_points_mean)\n",
    "\n",
    "A função passada para o map(), deve esperar u único valor da série (um valor pontual) e retornar uma versao transformada desse valor. o map() retorna uma nova série onde todos os valores deve ser transformados pela função utilizada. \n",
    "\n",
    "* o apply(): é um método equivalente se quiser transformar todo o DataFrame chamndo pelo método customizado em cada linha. \n",
    "\n",
    "> def remean_points(row):\n",
    ">    row.points = row.points - review_points_mean\n",
    ">    return row\n",
    "\n",
    "> reviews.apply(remean_points, axis='columns')\n",
    "\n",
    "Se chamar reviews.apply() com axis='index', então ao invés de alterar cada linha, nós passaremos uma função para alterar cada coluna.\n",
    "\n",
    "Note que o map() e o apply() retornam novos valores, transformando Series e DataFrames respectivamente. Eles não modificam o dado original. Se olharmos a primeira linha do dataframe original veremos que não foi modificado.\n",
    "\n",
    "O Pandas fornecem muitas operações comuns de mapeamentos. Por exemplo, aqui tem um novo jeito de fazer a alteração da média de pontos em colunas:\n",
    "\n",
    "> review_points_mean = reviews.points.mean()\n",
    "> reviews.points - review_points_mean\n",
    "\n",
    "Nesse código estamos fazendo uma operação em vários valores, do lado esquerdo (Na série) em um únio valor do lado direito (o valor da média). O Pandas vê esta expressão como subtrair o valor da média de cada valor do dataset.\n",
    "\n",
    "O Pandas também irá entender que se for fazer essa operação entre Série de igual tamanho. Por exemplo um jeito  fácil de combinar duas informações de país e região de um dataset é:\n",
    "\n",
    "> reviews.country + \" - \" + reviews.region_1\n",
    "\n",
    "Essa operação é mais rápido que o map() ou o apply() por não precisar acessar a biblioteca do Pandas. Todos os operadores conhecidos do Python (>, <, ==, and so on), pode trabalhar da mesma maneira.\n",
    "\n",
    "No entanto, eles não são tão flexíveis como o map() e o apply() e podem fazer coisas mais avançasdas, como aplicar lógica condicional, que não pode ser feito com apenas a adição ou substração sozinhas.\n",
    "\n",
    "Para verificar a mediana, pode-se utilizar a função median da biblioteca pandas\n",
    "> reviews.points.median()\n",
    "\n",
    "Uma função que retorna os valores únicos de uma coluna é o unique()\n",
    "\n",
    "> reviews.country.unique()\n",
    "\n",
    "Para contar a quantidade de valores únicos em uma coluna, por exemplo a quantidade de vezes que um determinado review foi feito de uma país, pode-se utilizar a função value_counts().\n",
    "\n",
    "> reviews_per_country = reviews.country.value_counts()\n",
    "\n",
    "Criar uma variável com valores central, isto é, uma versão com o valor de uma coluna subtraído do valor médio, muito comum como pre-processamento antes de aplicar muitos algoritmos de machine learning.\n",
    "\n",
    "> centered_price = (reviews.price - reviews.price.mean())\n",
    "\n",
    "\n",
    "A função idxmax pega o índice do maior valor entre colunas, já o loc como visto anteriormente busca o item da coluna referente aquele valor pesquisado. Então no exemplo abaixo, é feita a criação de um valor utilizando o valor de duas colunas e buscando o nome que tem tem o índice referente a este valor:\n",
    "\n",
    "> bargain_idx = (reviews.points/reviews.price).idxmax()\n",
    "> bargain_wine = reviews.loc[bargain_idx, 'title']\n",
    "\n",
    "Para contar um determinado valor dentro das linhas de uma coluna específica, e fazer isso para dois tipos de valores de entrada e depois transformar essas quantidades em uma série, é necessário usar a função MAP.\n",
    "\n",
    ">n_trop = reviews.description.map(lambda desc: \"tropical\" in desc).sum()\n",
    "> n_fruity = reviews.description.map(lambda desc: \"fruity\" in desc).sum()\n",
    "> descriptor_counts = pd.Series([n_trop, n_fruity], index=['tropical', 'fruity'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groupping and sorting\n",
    "\n",
    "Os maps nos permite transforma dados em DataFrame ou Series, um valor por ver para cada entrada na coluna. No entanto, frequentemente, queremos agrupar nossos dados em algum grupo específico de dados.\n",
    "\n",
    "Podemos fazer isso com a operacão groupby(). \n",
    "\n",
    "### Análise do Groupwise\n",
    "Uma função muito utilizada é a value_counts(). Podemos replicar o que ela faz da seguinte forma:\n",
    "\n",
    "> reviews.groupby('points').points.count()\n",
    "\n",
    "O groupby() cria um grupo de reviews que permite alocar o mesmos vaores de pontos a um dado vinho. E então para cada um desses grupos, pegamos a coluna points() e contamos quantas vezes ela aparece. O value_counts() é apenas um atalho para a operação de groupby().\n",
    "\n",
    "Podemos usar qualquer função de resumo(summary) utilizada antes. Por exemplo, para ter o valor mais barato dos vinhos em cada categoria de pontos, podemos fazer da seguinte forma:\n",
    "\n",
    "> reviews.groupby('points').price.min()\n",
    "\n",
    "Pode se pensar que cada grupo gerado é um pedaço do DataFrame, contendo apenas os dados com valores que queremos. Este DataFrame é acessível por nós usando o método apply(), e podemos manipular os dados de qualquer forma. Por exemplo, abaixo está uma forma de selecionar o primeiro nome do vinho revisado, de cada vinicula do dataset:\n",
    "\n",
    "> reviews.groupby('winery').apply(lambda df: df.title.iloc[0])\n",
    "\n",
    "Para um controle ainda mais fino, é possível agrupar os dados por mais de uma coluna, abaixo por exemplo, encontramos o melhor vinho por país e província:\n",
    "\n",
    "> reviews.groupby(['country', 'province']).apply(lambda df: df.loc[df.points.idxmax()])\n",
    "\n",
    "Um outro bom método do groupby() é o agg(), que nos permite rodar diferentes funções no nosso DataFrame, simultaneamente. Por exemplo, podemos gerar um resumo estatístico simples do dataset:\n",
    "\n",
    ">reviews.groupby(['country']).price.agg([len, min, max])\n",
    "\n",
    "Efetivamente o groupby() nos permite uma série de coisas poderosas.\n",
    "\n",
    "### Multi indexes\n",
    "\n",
    "Em todos os exemplos nós temos trabalhado com DataFrames ou Séries com objetos indexados por um único label. O groupby() é um pouco diferente no fato de que dependendo da operação que formos rodar ele as vezes resulta no que chamamos de multi-index. \n",
    "\n",
    "Um multi-index difere do index noraml, por ter muitos níves, por exemplo:\n",
    "\n",
    "> countries_reviewed = reviews.groupby(['country', 'province']).description.agg([len])\n",
    "> countries_reviewed\n",
    "\n",
    ">mi = countries_reviewed.index\n",
    "> type(mi)\n",
    "\n",
    "\n",
    "Multi-indices tem diversos métodos para lidar com suas estruturas em camadas, que não existe em indices únicos. Eles também precisam de 2 níveis de labels para devolver um valor, lidar com saídas de multi-index é comum para lida com pandas. \n",
    "\n",
    "Existem alguns casos de usos na documentação do Pandas em MultiIndex / Advanced Selection.\n",
    "\n",
    "No entando, de uma forma geral, o méotodo do multi-index que mais iremos utilizar é o de converter para um index único, que é o métodos reset_index():\n",
    "\n",
    "> countries_reviewed.reset_index()\n",
    "\n",
    "### Sorting\n",
    "\n",
    "Olhando novamente para as countries_reviewed, ao agrupá-los, nos retorna os dads na ordem do index e náo na ordem de valores. Isto é, o resultad do groupby as ordens das linhas é depedendete dos valores do index não dos dados. \n",
    "\n",
    "Para ter os dados na ordem que queremos, nós teremos que fazer a ordenação. O método sort_values() é útil para isso:\n",
    "\n",
    "> countries_reviewed = countries_reviewed.reset_index()\n",
    "> countries_reviewed.sort_values(by='len')\n",
    "\n",
    "O sort_values() por padrão ordena de forma crescente onde o primeiro valor é o menor. No entanto na maioria das vezes queremos a ordem decrescente, onde o maior número vem primeiro e para isso devemos fazer:\n",
    "\n",
    "> countries_reviewed.sort_values(by='len', ascending=False)\n",
    "> reviews_per_region = reviews.region_1.sort_values(ascending=False)\n",
    "\n",
    "Para ordenar por valores de index, utilizar o método sort_index(). Esse método te os mesmos argumentos padrões que a anterior:\n",
    "\n",
    "> countries_reviewed.sort_index()\n",
    "\n",
    "Por fim, é importante saber que pode-se ordenar mais de uma coluna por vez:\n",
    "\n",
    ">countries_reviewed.sort_values(by=['country', 'len'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datas Types and Missing Values\n",
    "\n",
    "## Dtypes\n",
    "\n",
    "O tipo de dados para uma coluna em um Dataframe ou em uma Séries é conhecido como dtype.\n",
    "Você pode usar a propriedade do dtype para pegar o tipo específico em uma coluna. Por exemplo, podemos pegar o dtype da coluna preço no review DataFrame:\n",
    "\n",
    "> reviews.price.dtype\n",
    "\n",
    "De forma similar a propriedade dtypes retorna o dtype de cada coluna.\n",
    "\n",
    "Os tipos de dados, nos dizem sobre como o pandas armazena seus dados internamente. float64 significa que ele está usando um ponto flutuate de 64-bit. int64 significa um inteiro de tamanho similar. \n",
    "\n",
    "Uma peculiaridade para ter em mente é que as colunas consistindo inteiramente de strings não tem seu próprio tipo. Elas no entanto dão o tipo do objeto. \n",
    "\n",
    "É possível converter uma coluna de um tipo, em outro, convertendo utilizando astype(). Por exemplo, podemos transformar a coluna pontos do tipo int64 para o tipo float64:\n",
    "\n",
    "> reviews.points.astype('float64')\n",
    "\n",
    "Um index de DataFrame ou Serie também seu tipo próprio:\n",
    "\n",
    "> reviews.index.dtype\n",
    "\n",
    "O pandas suporta também tipos mais exóticos, como tipos categóricos e dados de tempo. Porque os tipos de dados são mais raramente utilizados.\n",
    "\n",
    "## Dados faltantes\n",
    "\n",
    "Entradas sem valores são registradas como NaN (abreviação de \"Not a Number\"). Por razões técnicas, esses valores NaN são sempre do tipo float64.\n",
    "\n",
    "O Pandas fornecem alguns métodos específicos dos dados faltantes. Para selecionar entradas NaN, pode-se usar o pd.isnull() ou sem complemento pd.notnull(), isso significa que usamos:\n",
    "\n",
    "> reviews[reviews.price.isnull()]\n",
    "\n",
    "Recolocar valores perdidos é uma operação comum. Pandas fornece um método útil para esse problema o fillna(), que provê algumas estratégias diferentes estratégias para mitigar esses dados. Por exemplo, nós podemos simplismente recolocar cada NaN com o \"Unknown\":\n",
    "\n",
    "> reviews.region_2.fillna(\"Unknown\")\n",
    "\n",
    "Ou podemos preencher cada valor faltante com o primeiro valor não nulo que aparecer depois, que vier logo depois no bano de dados. Isto é conhecido como estratégia backfill.\n",
    "\n",
    "Alternativamente, nós devemos ter um valor não nulo que queremos recolocar. Por exemplo, vamos supor que após o dataset ter sido publicado, um revisor mude sua conta no twitter. Uma forma de refletir isso no dataset seria utilizando o método replace():\n",
    "\n",
    "> reviews.taster_twitter_handle.replace(\"@kerinokeefe\", \"@kerino\")\n",
    "\n",
    "O replace() é mencionado aqui, pois é útil para trocar valores inexistentes, por dados que dê algum tipo de sentido ao valor do dataset, como por exemplo algo como: \"Unknown\", \"Undisclosed\", \"Invalid\" e outros."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renomeando e combinando\n",
    "\n",
    "A função rename() permite trocar o nome do index e/ou os nomes das colunas. Por exemplo, para mudar a coluna \"points\" para \"score\":\n",
    "\n",
    "> reviews.rename(columns={'points': 'score'})\n",
    "\n",
    "O rename() permite trocar o nome do index ou coluna especificando um paramêtro chave para cada um deles. Isso suporta uma variedade de formatos de entrada, mas normalmente no dicinário de Python é mais conveniente. Aqui um exemplo, utilizado para renomear alguns elementos do index: \n",
    "\n",
    "> reviews.rename(index={0: 'firstEntry', 1: 'secondEntry'})\n",
    "\n",
    "Com muita frequencia, precisamos renomear os nomes das colunas, mas raramente os dos index. Para isso, o set_index() é normalmente mais conveniente. \n",
    "\n",
    "Ambos a linha do index e a coluna index pode ter seus próprioes atributo de nome. O método complementar rename_axis() deve ser usada para trocar esses nomes:\n",
    "\n",
    "> reviews.rename_axis(\"wines\", axis='rows').rename_axis(\"fields\", axis='columns')\n",
    "\n",
    "## Combinando\n",
    "\n",
    "Quando executamos operações nos datasets, as vezes precisamos combinar diferentes DataFrames e/ou séries de formas não triviais. O pandas tem 3 métodos core, para fazer isso. Em ordem de complexidade, são: concat(), join() e o merge(). A maior parte do que o merge() faz pode ser feito simplimente com  o join(), então nesse tutorial será focado apenas nos dois primeiros. Depois tenho que pesquiser sobre o merge() se houver necessidade.\n",
    "\n",
    "A forma mais simples de combinar é o concat(), dada uma lista de elementos essa função irá distribuir esses elementos juntos ao longo do eixo.\n",
    "\n",
    "Essa função é útil, quando temos dados em diferentes DataFrame ou objetos de serie em um mesmo campo (coluna). Um eemplos é no data set de vídeos do Youtube, que divide os dados baseado no país de origem. Se nós queremos estudar multiplos países simultaneamente, nós precisamos usar o contact(), para usarmos juntos:\n",
    "\n",
    "> canadian_youtube = pd.read_csv(\"../input/youtube-new/CAvideos.csv\")\n",
    "> british_youtube = pd.read_csv(\"../input/youtube-new/GBvideos.csv\")\n",
    "\n",
    "> pd.concat([canadian_youtube, british_youtube])\n",
    "\n",
    "\n",
    "O join() (é o mesmo do SQL praticamente) o permite combinar diferentes objetos de DataFrame que possuam um index em comum. Por exemplo, para baixar vídeos que tornaram-se trending no mesmo dia tanto no Canada quanto em UK, poderíamos fazer da seguinte forma:\n",
    "\n",
    "left = canadian_youtube.set_index(['title', 'trending_date'])\n",
    "right = british_youtube.set_index(['title', 'trending_date'])\n",
    "\n",
    "> left.join(right, lsuffix='_CAN', rsuffix='_UK')\n",
    "\n",
    "Neste caso os parâmetros lsuffix e o rsuffix são necessários, pois os dados tem o mesmo nome de colunas tanto na tabela do Canda quanto em UK. Se isso não fosse verdade, não precisaria utilizar. (Se não fosse a mesma estrutura de datasets com dados diferentes de cada país)\n",
    "\n",
    "Agora um exemplo de como fazer um join entre dois dataFrames, utilizando como pivô (coluna em comum) a coluna MeetID\n",
    "\n",
    "> left = powerlifting_meets.set_index('MeetID') \n",
    "> right = powerlifting_competitors.set_index('MeetID')\n",
    "> powerlifting_combined = left.join(right)\n",
    "\n",
    "ou\n",
    "\n",
    "> powerlifting_combined = powerlifting_meets.set_index('MeetID').join(powerlifting_competitors.set_index('MeetID'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 109: expected 3 fields, saw 4\\nSkipping line 535: expected 3 fields, saw 4\\nSkipping line 647: expected 3 fields, saw 4\\nSkipping line 1072: expected 3 fields, saw 4\\n'\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tabela = pd.read_csv('/home/bruno/teste_2.csv', sep=';', header=None, error_bad_lines=False)\n",
    "unique_table = tabela.drop_duplicates()\n",
    "unique_table.head()\n",
    "unique_table.to_csv(r'/home/bruno/teste_compiled.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
